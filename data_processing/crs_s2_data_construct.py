import json
import os
import argparse

def convert_punctuation(input_string):
    
    punc_en = """!?",;:.'"""
    punc_cn = """！？”，；：。‘"""

    trans_table = str.maketrans(punc_en, punc_cn)

    return input_string.translate(trans_table)


parser = argparse.ArgumentParser(description='Merge the results of LLMs in the fist stage with the original data to construct the training data of the second stage for CRSs')

parser.add_argument("--llm_train_data_path", type=str, default='xx', help="Path to the json data constructed for training LLMs (the first stage)")
parser.add_argument("--llm_res_data_path", type=str, default='xx', help="Path to the txt data of result generated by LLMs (the first stage)")
parser.add_argument("--llm_type", type=str, default='alpaca', help="type of LLMs trained in the first second (In our work, it may be chatglm or alpaca)")
parser.add_argument("--data_save_path", type=str, default='xx', help="Path to the json data constructed to train CRSs (the second stage)")


if __name__ == '__main__':
    
    args = parser.parse_args()
    
    llm_stage1_train_data_path = args.llm_train_data_path
    llm_stage1_result_path = args.llm_res_data_path
    crs_stage2_train_data_path = args.data_save_path

    llm_stage1_train_file_list = ['train_sample.json', 'valid_sample.json', 'test_sample.json'] # 一般不必修改，因为llm_stage1_train_data已经生成
    llm_stage1_result_file_list = ['{}_predict_sta1_train.txt'.format(args.llm_type), '{}_predict_sta1_val.txt'.format(args.llm_type), '{}_predict_sta1_test.txt'.format(args.llm_type)]
    crs_stage2_train_file_list = ['train_sample.json', 'valid_sample.json', 'test_sample.json']

    result_attr = '{}_predict_result'.format(args.llm_type)

    for i, llm_stage1_result_file in enumerate(llm_stage1_result_file_list):
        llm_stage1_train_data_file = os.path.join(llm_stage1_train_data_path, llm_stage1_train_file_list[i])
        with open(llm_stage1_train_data_file, 'r', encoding='utf-8') as file:
            ori_data_json_list = json.load(file)
        ori_data_not_null_list = []
        for item in ori_data_json_list:
            if item['output_llm'] != '':
                ori_data_not_null_list.append(item)

        llm_stage1_result_file = os.path.join(llm_stage1_result_path, llm_stage1_result_file)
        
        llm_json_list = []
        
        with open(llm_stage1_result_file, 'r') as f:
            for line in f:
                llm_json_list.append(json.loads(line))

        if len(ori_data_not_null_list) == len(llm_json_list):
            print(True)
        else:
            print(False)
        for num in range(len(ori_data_not_null_list)):
            ori_data_not_null_list[num][result_attr] = convert_punctuation(llm_json_list[num]['predict'])

        crs_stage2_train_data_file = os.path.join(crs_stage2_train_data_path, crs_stage2_train_file_list[i])
        with open(crs_stage2_train_data_file, 'w', encoding='utf-8') as file:
            json.dump(ori_data_not_null_list, file, ensure_ascii=False, indent=4)

