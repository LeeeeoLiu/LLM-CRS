import os
import json
import jsonlines
import argparse

TASKS = ['Understand', 'Elicit', 'Recommend', 'Response']

def prepare_data_retrain(dataset_name, base_crs_output_attr):
    with open(dataset_name, 'r', encoding='utf-8') as f:
        dataset = json.load(f)
    for data in dataset:
        dia_domain = data["domain"]
        input_llm = data["input_llm"]
        if data["task_name"] == TASKS[0]:
            instruction_stage2 = "根据{}售前对话，并参考对话式推荐系统的识别结果，识别当前用户或者客服输入中涉及的商品相关的属性值和对应的属性。\n针对用户输入，需要识别出属性和属性值。客服输入中属性值可能为空。".format(
                dia_domain)
            input_llm_stage2 = input_llm + '\n对话式推荐系统识别的结果：{}'.format(data[base_crs_output_attr])

        elif data["task_name"] == TASKS[1]:
            instruction_stage2 = "根据{}售前对话，并参考对话式推荐系统的属性预测结果，选择一系列的属性，来引导用户提供更多关于需求的偏好信息。结果中可以包含属性值，也可以不包含属性值。".format(dia_domain)
            input_llm_stage2 = input_llm + '\n对话式推荐系统预测的属性：{}'.format(data[base_crs_output_attr]) # todo list-> str

        elif data["task_name"] == TASKS[2]:
            instruction_stage2 = "根据{}售前对话中用户表达的需求和偏好信息以及候选商品信息，并参考对话式推荐系统的商品推荐排序结果，从候选商品A-T中选择最有可能满足用户需求、偏好的商品推荐给用户。".format(dia_domain)
            
            item_list = data['candidate']
            base_crs_output = data[base_crs_output_attr]
            index_list = [chr(item_list.index(item) + 65) for item in base_crs_output]
            substring = '\n各候选商品对应的属性和属性值：'
            index_insert_input = input_llm.find(substring)
            input_llm_stage2 = input_llm[:index_insert_input] + '\n对话式推荐系统推荐的Top1-20商品排序结果：{}'.format('、'.join(index_list)) + input_llm[index_insert_input:]

        elif data["task_name"] == TASKS[3]:
            instruction_stage2 = "根据{}售前对话中已获取的信息、引导用户需求的属性、满足用户需求的商品信息，并参考对话式推荐系统生成的回复，生成回应用户需求且用户容易理解的通俗回复。".format(dia_domain)
            input_llm_stage2 = input_llm + '\n对话式推荐系统生成的回复：{}'.format(data[base_crs_output_attr])


        data["instruction_stage2"] = instruction_stage2
        data["input_llm_stage2_cpt"] = input_llm_stage2

    return dataset

parser = argparse.ArgumentParser(description='Merge the results of CRSs in the fist stage with the original data to construct the training data of the second stage for LLMs')

parser.add_argument("--crs_res_data_path", type=str, default='xx', help="Path to the json data of result generated by CRSs (the first stage)")
parser.add_argument("--crs_type", type=str, default='alpaca', help="type of CRS trained in the first second (In our work, it may be cpt or bart)")
parser.add_argument("--data_save_path", type=str, default='xx', help="Path to the json data constructed to train LLMs (the second stage)")


if __name__ == '__main__':
        
    args = parser.parse_args()
    dataset_path = args.crs_res_data_path
    base_crs_output_attr = "{}_base_crs_output".format(args.crs_type)
    train_data_path_stage2 = args.data_save_path

    data_file_name_list = ['train_samples.json', 'valid_samples.json', 'test_samples.json']
    data_type = ['train_sample', 'valid_sample', 'test_sample']

    for i, data_file_name in enumerate(data_file_name_list):

        result_list = prepare_data_retrain(os.path.join(dataset_path, 'merge_'+data_file_name), base_crs_output_attr)

        with open(os.path.join(train_data_path_stage2, data_type[i]+'.json'), 'w', encoding='utf-8') as f:
            json.dump(result_list, f, ensure_ascii=False, indent=4)

